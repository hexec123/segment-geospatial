{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Segmentation with SAM 3\n",
    "\n",
    "[![image](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/opengeos/segment-geospatial/blob/main/docs/examples/sam3_video_segmentation.ipynb)\n",
    "\n",
    "This notebook demonstrates how to use SAM 3 for video segmentation and tracking. SAM 3 provides:\n",
    "\n",
    "- **Text prompts**: Segment objects using natural language (e.g., \"person\", \"car\")\n",
    "- **Point prompts**: Add clicks to segment and refine objects\n",
    "- **Object tracking**: Track segmented objects across all video frames\n",
    "- **Time series support**: Process GeoTIFF time series with georeferencing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "SAM 3 requires CUDA-capable GPU. Install with:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"segment-geospatial[samgeo3]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use SamGeo 2, install it as:\n",
      "\tpip install segment-geospatial[samgeo2]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from samgeo import SamGeo3Video, download_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Video Predictor\n",
    "\n",
    "The `SamGeo3Video` class provides a simplified API for video segmentation. It automatically uses all available GPUs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[32mINFO 2025-12-09 09:47:37,365 742413 sam3_video_predictor.py: 299:\u001b[0m using the following GPU IDs: [0, 1]\n",
      "\u001b[0m\u001b[32mINFO 2025-12-09 09:47:37,474 742413 sam3_video_predictor.py: 315:\u001b[0m \n",
      "\n",
      "\n",
      "\t*** START loading model on all ranks ***\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[32mINFO 2025-12-09 09:47:37,474 742413 sam3_video_predictor.py: 317:\u001b[0m loading model on rank=0 with world_size=2 -- this could take a while ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPUs: [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[32mINFO 2025-12-09 09:47:41,473 742413 sam3_video_base.py: 124:\u001b[0m setting max_num_objects=10000 and num_obj_for_compile=16\n",
      "\u001b[0m\u001b[32mINFO 2025-12-09 09:47:43,364 742413 sam3_video_predictor.py: 319:\u001b[0m loading model on rank=0 with world_size=2 -- DONE locally\n",
      "\u001b[0m\u001b[32mINFO 2025-12-09 09:47:43,364 742413 sam3_video_predictor.py: 376:\u001b[0m spawning 1 worker processes\n",
      "\u001b[0m\u001b[32mINFO 2025-12-09 09:47:44,970 743079 sam3_video_predictor.py: 460:\u001b[0m starting worker process rank=1 with world_size=2\n",
      "\u001b[0m\u001b[32mINFO 2025-12-09 09:47:45,079 743079 sam3_video_predictor.py: 317:\u001b[0m loading model on rank=1 with world_size=2 -- this could take a while ...\n",
      "\u001b[0m\u001b[32mINFO 2025-12-09 09:47:48,917 743079 sam3_video_base.py: 124:\u001b[0m setting max_num_objects=10000 and num_obj_for_compile=16\n",
      "\u001b[0m\u001b[32mINFO 2025-12-09 09:47:50,706 743079 sam3_video_predictor.py: 319:\u001b[0m loading model on rank=1 with world_size=2 -- DONE locally\n",
      "\u001b[0m\u001b[32mINFO 2025-12-09 09:47:50,706 743079 sam3_video_predictor.py: 469:\u001b[0m started worker rank=1 with world_size=2\n",
      "\u001b[0m\u001b[32mINFO 2025-12-09 09:47:50,707 742413 sam3_video_predictor.py: 410:\u001b[0m spawned 1 worker processes\n",
      "\u001b[0m\u001b[32mINFO 2025-12-09 09:47:50,932 742413 sam3_video_predictor.py: 330:\u001b[0m \n",
      "\n",
      "\n",
      "\t*** DONE loading model on all ranks ***\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sam = SamGeo3Video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Video\n",
    "\n",
    "You can load from different sources:\n",
    "- MP4 video file\n",
    "- Directory of JPEG frames\n",
    "- Directory of GeoTIFFs (for remote sensing time series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/opengeos/datasets/releases/download/videos/cars.mp4\"\n",
    "video_path = download_file(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SamGeo3Video.set_video() got an unexpected keyword argument 'image_output_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# sam.set_video(video_path)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43msam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mabspath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/data/sam3/sources/IMG_4346.MOV\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_output_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./output/images\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: SamGeo3Video.set_video() got an unexpected keyword argument 'image_output_dir'"
     ]
    }
   ],
   "source": [
    "# sam.set_video(video_path)\n",
    "sam.set_video(os.path.abspath(\"/data/sam3/sources/IMG_4346.MOV\"), frame_rate=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.show_video(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-Prompted Segmentation\n",
    "\n",
    "Use natural language to describe objects. SAM 3 finds all instances and tracks them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment all car in the video\n",
    "sam.generate_masks(\"circular connector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first frame with masks\n",
    "sam.show_frame(0, axis=\"on\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/user-attachments/assets/563dcda7-24e2-43f5-95b1-5706f72a3cc0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show multiple frames in a grid\n",
    "sam.show_frames(frame_stride=50, ncols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/user-attachments/assets/cc08c90b-3227-4bcd-acfa-2cb3e6c89bc5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Objects\n",
    "\n",
    "Remove specific objects by ID and re-propagate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove object 2 and re-propagate\n",
    "sam.remove_object(2)\n",
    "sam.propagate()\n",
    "sam.show_frame(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/user-attachments/assets/d4d98bf1-4580-466d-a7dc-19485fbeb466)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Prompts\n",
    "\n",
    "Add objects back or refine segmentation using point prompts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add back object 2 with a positive point click\n",
    "sam.add_point_prompts(\n",
    "    points=[[335, 203]],  # [x, y] coordinates\n",
    "    labels=[1],  # 1=positive, 0=negative\n",
    "    obj_id=2,\n",
    "    frame_idx=0,\n",
    ")\n",
    "sam.propagate()\n",
    "sam.show_frame(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/user-attachments/assets/dc1f1b64-654a-4c57-a892-2679e02ffe29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refine with Multiple Points\n",
    "\n",
    "Use positive and negative points to refine the mask.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine to segment only the shirt (not pants)\n",
    "sam.add_point_prompts(\n",
    "    points=[[335, 195], [335, 220]],  # detect windshield, not the car\n",
    "    labels=[1, 0],  # positive, negative\n",
    "    obj_id=2,\n",
    "    frame_idx=0,\n",
    ")\n",
    "sam.propagate()\n",
    "sam.show_frames(frame_stride=20, ncols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/user-attachments/assets/48b454d8-ba9c-43df-b001-fba6f86792b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Save masks as images or create an output video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# Save mask images\n",
    "sam.save_masks(\"output/masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save video with blended masks\n",
    "sam.save_video(\"output/segmented.mp4\", fps=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close Session\n",
    "\n",
    "Close the session to free GPU resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To completely shutdown and free all resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_sam3 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
